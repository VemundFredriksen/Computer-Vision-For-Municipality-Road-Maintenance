# Set worker processes automatically depending on server CPUs - scalable
# the user for this process is nginx
user nginx;
worker_processes auto;

# Errors should be put into a log
# In case you only want to see critical logs specify crit instead of warn
error_log /var/log/nginx/error.log warn;

# The pid of this process should be nginx
pid /var/run/nginx.pid;

# File descriptors used for NGINX, overrides OS settings
# default value is 2000, should be tweaked later.
worker_rlimit_nofile 4000;

# Directives directly involved in connection processing
events {
    # Amount of clients served are per worker
    # Rough calculation of max clients will be: 
    # CPU cores * connections | worker_processes * worker_connections
    # default setting is 1024
    worker_connections 3000;

    # # Accept many connections to boost performance (NB! using HTTP/2 now)
    # # May cause server overload upon DoS or flood if worker_connections
    # # is not adequate, should be disabled if experiencing attacks
    # multi_accept on;

    # # Each thread shold serve as many clients as possible, using epoll
    # use epoll;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # # Attempt to cache FD (file descriptions) frequently accessed files
    # # Should be tweaked depending on conditions
    # open_file_cache max=200000 inactive=20s;
    # open_file_cache_valid 30s;
    # open_file_cache_min_uses 2;
    # open_file_cache_errors on;

    # Copy data between FD's within the kernel, faster than regular read/write I/O
    sendfile on;

    # Headers should be sent immediately than on an individual basis
    tcp_nopush on;

    # Do not buffer sent data which optimizes for small real-time data burst access
    tcp_nodelay on;

    # Turn on access log, useful for development, otherwise uncomment the below line
    #access_log off;
    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;


    # # ********************************************
    # # NB: THIS IS A TEST AND SHOULD NOT BE USED IN PRODUCTION
    # # BEFORE IT HAS BEEN TESTED PROPERLY

    # # Compress data sent using gzip
    # gzip on;

    # gzip_disable msie6;
    # gzip_vary on;
    # gzip_min_length 10240;
    # gzip_comp_level 1;
    # gzip_proxied expired no-cache no-store private auth;

    # gzip_types
    #     # text/html GZIP module does html automatically, 
    #     # will cause duplicate warning if uncommented
    #     text/xml
    #     text/plain
    #     text/javascript
    #     text/css
    #     image/svg+xml
    #     application/json
    #     application/xml
    #     application/javascript
    #     application/x-javascript
    #     application/rss+xml
    #     application/atom+xml;

    # # NB: THIS IS A TEST AND SHOULD NOT BE USED IN PRODUCTION
    # # ********************************************

    # In order to avoid flooding with with multi_accept and HTTP/2 client 
    # should be timed-out quickly to free up server memory
    # the default value is 60 secounds
    send_timeout 2;

    # Requests have a time-out of 10 secounds, default is 60 secounds
    client_body_timeout 10;
    
    # Connections will close automatically after 30 secounds, low keepalive timeout
    # default value is 75 secounds
    keepalive_timeout 30;

    # If the client is not responding, then close the connection - avoid flood&free up memory
    reset_timedout_connection on;

    # # Number of keep-alive requests a client can make - NB: needs to be tweaked!
    # keepalive_requests 30000;

    # IMPORTANT! setting below, import the vhosts settings specified in the conf.d directory
    include /etc/nginx/conf.d/*.conf;
}